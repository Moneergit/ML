{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "## Implementing a dummy binary-classifier with fit-predict interface\n",
    "\n",
    "We begin with the MNIST data-set and will reuse the data loader from Scikit-learn. Next we create a dummy classifier, and compare the results of the SGD and dummy classifiers using the MNIST data...\n",
    "\n",
    "#### Qa  Load and display the MNIST data\n",
    "\n",
    "There is a `sklearn.datasets.fetch_openml` dataloader interface in Scikit-learn. You can load MNIST data like \n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_openml\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784',??) # needs to return X, y, replace '??' with suitable parameters! \n",
    "# Convert to [0;1] via scaling (not always needed)\n",
    "#X = X / 255.\n",
    "```\n",
    "\n",
    "but you need to set parameters like `return_X_y` and `cache` if the default values are not suitable! \n",
    "\n",
    "Check out the documentation for the `fetch_openml` MNIST loader, try it out by loading a (X,y) MNIST data set, and plot a single digit via the `MNIST_PlotDigit` function here (input data is a 28x28 NMIST subimage)\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "```\n",
    "\n",
    "Finally, put the MNIST loader into a single function called `MNIST_GetDataSet()` so you can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importer nødvendige biblioteker\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Funktion til at plotte et MNIST billede\n",
    "def MNIST_PlotDigit(data):\n",
    "    # Reshaper dataen fra en flad array til en 28x28 matrix\n",
    "    image = data.reshape(28, 28)\n",
    "    # Plot billede med 'binary' colormap (sort-hvidt)\n",
    "    plt.imshow(image, cmap='binary', interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")  # Skjul akserne\n",
    "    plt.show()\n",
    "\n",
    "# Funktion til at hente MNIST datasættet\n",
    "def MNIST_GetDataSet():\n",
    "    # Hent MNIST datasættet via OpenML\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "    \n",
    "    # Normalisering: Skaler dataene til intervallet [0, 1] ved at dele med 255\n",
    "    X = X / 255.0\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Hent datasættet\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "# Vis et eksempel på et billede (vælg den første datapunkt)\n",
    "MNIST_PlotDigit(X[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb  Add a Stochastic Gradient Decent [SGD] Classifier\n",
    "\n",
    "Create a train-test data-set for MNIST and then add the `SGDClassifier` as done in [HOML], p.103.\n",
    "\n",
    "Split your data and run the fit-predict for the classifier using the MNIST data.(We will be looking at cross-validation instead of the simple fit-predict in a later exercise.)\n",
    "\n",
    "Notice that you have to reshape the MNIST X-data to be able to use the classifier. It may be a 3D array, consisting of 70000 (28 x 28) images, or just a 2D array consisting of 70000 elements of size 784.\n",
    "\n",
    "A simple `reshape()` could fix this on-the-fly:\n",
    "```python\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "```\n",
    "\n",
    "Remember to use the category-5 y inputs\n",
    "\n",
    "```python\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "```\n",
    "instead of the `y`'s you are getting out of the dataloader. In effect, we have now created a binary-classifier, that enable us to classify a particular data sample, $\\mathbf{x}(i)$ (that is a 28x28 image), as being a-class-5 or not-a-class-5. \n",
    "\n",
    "Test your model on using the test data, and try to plot numbers that have been categorized correctly. Then also find and plots some misclassified numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(70000, 784)\n",
      "X.shape=(70000, 784)\n",
      "Accuracy of the SGD Classifier: 97.60%\n",
      "Number of correctly classified '5's: 1031\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importer nødvendige biblioteker\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Funktion til at hente MNIST datasættet\n",
    "def MNIST_GetDataSet():\n",
    "    # Hent MNIST datasættet via OpenML\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "    \n",
    "    # Normalisering: Skaler dataene til intervallet [0, 1] ved at dele med 255\n",
    "    X = X / 255.0\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Hent MNIST datasættet\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "# Vis dimensioner af X og y\n",
    "print(f\"X.shape={X.shape}\")  # Forventet at X.shape = (70000, 784)\n",
    "\n",
    "# Skift data til 2D array, hvis nødvendigt\n",
    "if X.ndim == 3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim == 1\n",
    "    X = X.reshape((X.shape[0], X.shape[1] * X.shape[2]))\n",
    "assert X.ndim == 2\n",
    "print(f\"X.shape={X.shape}\")  # X.shape = (70000, 784)\n",
    "\n",
    "# Split datasættet i træning og test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Opret en binær målvariabel, hvor vi skelner mellem tallet 5 og ikke-5\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "\n",
    "# Initialiser SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "\n",
    "# Træn classifieren\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Forudsig på testdataene\n",
    "y_pred_5 = sgd_clf.predict(X_test)\n",
    "\n",
    "# Beregn nøjagtigheden\n",
    "accuracy = accuracy_score(y_test_5, y_pred_5)\n",
    "print(f\"Accuracy of the SGD Classifier: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Funktion til at plotte et billede\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap='binary', interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")  # Skjul akserne\n",
    "    plt.show()\n",
    "\n",
    "# Find og vis korrekt klassificerede billeder, der er 5\n",
    "correct_5_indices = np.where((y_pred_5 == True) & (y_test_5 == True))[0]\n",
    "print(f\"Number of correctly classified '5's: {len(correct_5_indices)}\")\n",
    "\n",
    "# Plot de første 3 korrekt klassificerede billeder, der er 5\n",
    "for i in correct_5_indices[:3]:\n",
    "    plot_digit(X_test[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc Implement a dummy binary classifier\n",
    "\n",
    "Now we will try to create a Scikit-learn compatible estimator implemented via a python class. Follow the code found on p.107 3rd [HOML] (for [HOML] 1. and 2. editions: name you estimator `DummyClassifier` instead of `Never5Classifyer`).\n",
    "\n",
    "Here our Python class knowledge comes into play. The estimator class hierarchy looks like\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L02/Figs/class_base_estimator.png\" alt=\"WARNING: could not get image from server.\" style=\"width:500px\">\n",
    "\n",
    "All Scikit-learn classifiers inherit from `BaseEstimator` (and possibly also `ClassifierMixin`), and they must have a `fit-predict` function pair (strangely not in the base class!) and you can actually find the `sklearn.base.BaseEstimator` and `sklearn.base.ClassifierMixin` python source code somewhere in you anaconda install dir, if you should have the nerves to go to such interesting details.\n",
    "\n",
    "But surprisingly you may just want to implement a class that contains the `fit-predict` functions, ___without inheriting___ from the `BaseEstimator`, things still work due to the pythonic 'duck-typing': you just need to have the class implement the needed interfaces, obviously `fit()` and `predict()` but also the more obscure `get_params()` etc....then the class 'looks like' a `BaseEstimator`...and if it looks like an estimator, it _is_ an estimator (aka. duck typing).\n",
    "\n",
    "Templates in C++ also allow the language to use compile-time duck typing!\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Duck_typing\n",
    "\n",
    "Call the fit-predict on a newly instantiated `DummyClassifier` object, and find a way to extract the accuracy `score` from the test data. You may implement an accuracy function yourself or just use the `sklearn.metrics.accuracy_score` function. \n",
    "\n",
    "Finally, compare the accuracy score from your `DummyClassifier` with the scores found in [HOML] \"Measuring Accuracy Using Cross-Validation\", p.107. Are they comparable? \n",
    "\n",
    "(Notice that Scikit-learn now also have a `sklearn.dummy.DummyClassifier`, but you are naturally supposed to create you own...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DummyClassifier: 90.91%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Implementer DummyClassifier\n",
    "class DummyClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, strategy='most_frequent'):\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.strategy == 'most_frequent':\n",
    "            # Find den mest hyppige klasse i træningsdataene\n",
    "            self.most_frequent_class_ = np.bincount(y.astype(int)).argmax()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Forudsig den mest hyppige klasse for hver input\n",
    "        return np.full(len(X), self.most_frequent_class_, dtype=int)\n",
    "\n",
    "# Hent MNIST datasættet\n",
    "def MNIST_GetDataSet():\n",
    "    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "    X = X / 255.0  # Normalisering\n",
    "    return X, y\n",
    "\n",
    "# Hent og del data\n",
    "X, y = MNIST_GetDataSet()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Skab en binær klassifikator for tallet 5\n",
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')\n",
    "\n",
    "# Initialiser DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Træn DummyClassifier\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "\n",
    "# Forudsig på testdataene\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# Beregn nøjagtigheden\n",
    "accuracy = accuracy_score(y_test_5, y_pred)\n",
    "print(f\"Accuracy of DummyClassifier: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qd concluding remarks in text.. \n",
    "\n",
    "#I disse øvelser har vi arbejdet med at implementere og evaluere forskellige klassifikatorer ved hjælp af Scikit-learn, herunder en Stochastic Gradient Descent (SGD) classifier og en simpel DummyClassifier. Formålet var at få praktisk erfaring med, hvordan man opbygger, træner og evaluerer modeller i machine learning, samtidig med at vi arbejder med et standard datasæt som MNIST.\n",
    "\n",
    "#Det var vigtigt at se på disse koncepter, fordi de giver en grundlæggende forståelse af, hvordan klassifikatorer fungerer, og hvordan man kan vurdere deres præstation. Vi lærte at anvende metoder som træning, forudsigelse og evaluering af modeller, samtidig med at vi introducerede begreber som binær klassifikation og cross-validation (som vi senere vil dykke dybere ned i).\n",
    "\n",
    "#Den overordnede læring var at forstå, hvordan simple modeller kan give en baseline, og hvordan vi kan sammenligne deres præstationer mod mere komplekse metoder som SGD for at vurdere, hvad der fungerer bedst i en given situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2018-12-19| CEF, initial.\n",
    "2018-02-06| CEF, updated and spell checked.\n",
    "2018-02-08| CEF, minor text update.\n",
    "2018-03-05| CEF, updated with SHN comments.\n",
    "2019-09-02| CEF, updated for ITMAL v2.\n",
    "2019-09-04| CEF, updated and added conclusion Q.\n",
    "2020-01-25| CEF, F20 ITMAL update.\n",
    "2020-02-04| CEF, updated page numbers to HOMLv2.\n",
    "2020-09-03| CEF, E20 ITMAL update, udpated figs paths.\n",
    "2020-09-06| CEF, added alt text.\n",
    "2020-09-18| CEF, added binary-classifier text to Qb to emphasise 5/non-5 classification.\n",
    "2021-01-12| CEF, F21 ITMAL update, moved revision tabel.\n",
    "2021-08-02| CEF, update to E21 ITMAL.\n",
    "2022-01-25| CEF, update to F22 SWMAL.\n",
    "2023-02-07| CEF, update HOML page numbers.\n",
    "2024-02-14| CEF, added note on sklearn.dummy.DummyClassifier.\n",
    "2024-09-13| CEF, updated p.107 and editions text references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.517px",
    "left": "1230px",
    "right": "20px",
    "top": "119px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
